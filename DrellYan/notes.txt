
Analysis steps:

1. Running on AODSIM original data and producing Bambu-style
(i.e. MIT framework) ntuples. This is done by someone else
for everyone using that framework on all datasets of interest.
The Bambu ntuples of a given dataset are the same for all
analyses that use this framework.

2. Running on Bambu files and producing analysis specific 
ntuples is done for us (presently by Kevin Sung/MIT).
At present, we get in these ntuples for each event:
  - event information block (event/run/lumi section, etc)
  - generator information about gamma*/Z, each of the two
      two daughter leptons, etc
  - electron collection, contains all electrons >9 GeV
  - muon collection, contains all muons >10 GeV
  - photon collection, all superclusters with Et>9 GeV
  - jet collection, contains Particle Flow jets 
         with L1, L2, L3 corrected jet Et>10 GeV,
         or non-trivial b-tag
  - dielectron collection contains all possible pairs
        from the electron collection
  - primary vertex collection: all "good" primary vertices

3. Running on analysis specific ntuples. We use the script
"plotDY.C" or varitations of it. This script performs
the final selection of events. To the data, it applies
final energy scale corrections and recomputes invariant 
mass. This script also performs good run selection according
to the JSON file of choice.
   The result of running this script is seveal plots
that open on canvases, but more importantly it is 
creation of a new directory that contains a ROOT file
for each sample (data, signal MC, and all background MC
samples), each ROOT file contains an ntuple in a very
simple format of selected events only, with just a few
basic quantities.
   The script is run this way:
.L plotDY.C+   (the + is strongly recommended)
plotDY("data.conf")
where data.conf is the configuration file name.
  The configuration file contains many fields, I can explain
each line in a call.

4. On the final ntuples output of the above one runs
the script "plotSelectDY.C". This script makes plots
in the format appropriate for the notes and papers,
and also tabulates the yields for data and MC in 
several different ways. 
.L plotSelectDY.C+
plotSelectDY("data.conf")
The configuration file "data.conf" is identical to the
one in the previous bullet.
  There is also output of this step for all yields
saved in a ROOT file in form of TVectorD arrays.

5. The next script repackages observed yields,
performs backgrund subtraction, propagates background
errors, and creates the next level ROOT file that 
has arrays for background-subtracted signal yields
and errors (statistical and systematic).
This script can be run simply as
.x repackage_signal_yields.C
Note: up to this point, our background estimate comes
from MC. The MC backgrounds are used for example to make
plots that go into papers. But what we really use for the
measurement, is the backgrounds estimated from data-driven
methods (such as e-mu or fake rates methods). The "repackage"
script introduces these backgrounds, and therefore needs
the data-driven background values. At the moment, these
come from RAL, who produce them for us using our ntuples.

6. Calculate acceptance using signal MC.

< the rest of explanations have been sent over email... >

-------------------------------------------

Open issues:

 - FEWZ reweighting is not done for all analysis pieces. Should
 it be? For example for efficiency corrections?

 - Pile-up reweighting is not done for all analysis pieces.
 For which should it be done? One should be careful and implement
 it coherently for event efficiency and efficiency from tag and probe.

 - Understand mass-dependent efficiency. Especially ID.

 - Add theory systematics to calcCrossSection.C
 
 - Make calcCrossSection read unfolding and escale systematics from ROOT files

 - Add code that measures this systematics:
   - energy scale
   - unfolding
   - FSR-related

 - Error on FSR corrections is not properly calculated. The calculation
  ignores correlation between numerator and denominator. As a result, 
  the error is very large for larger mass bins.

 - It may be possible to tighten the tag cuts in tag and probe to
  reduce backgrounds and therefore improve accuracy for lower Pt bins.

 - We are asked to consider doing a study in tag and probe
  where we do not use counting method at all, but instead use
  fit. For MC, background can be added by hand.

 - For the whole analysis, should we consider relaxing electron ID cuts,
   given that we have so little background? A study would be needed
   to answer this question.

 - Should tag and probe be done with more eta or pt bins?

 - What are the exact reasons that the event efficiency is lower
   in 2011 than in 2010, significantly for lower mass?

 - Can we investigate the origin of the rising background in
   certain bins of tag and probe fits? Is it perhaps related
   to ttbar?

 - What is the difference between the efficiency scale factor
   for given mass bin found as the average of scale factors
   among all events using the nominal calibration vs the average
   over 100 resmeared calibration sets? Which one is the right
   one to use?

 - One has to check whether errors are calculated correctly
   for Acc, Eff, etc, when many signal MC samples are combined
   with weights.

 - The MC closure test of unfolding, done when the script calcCrossSection.C
   is executed, does not return a perfect result. Investigate why.

Completed tasks:

 - Now subtractBackgrounds.C wants split di-bosons, while for
 figures from plotSelectDY.C we have them combined. This should
 be reconciled.
    This has been changed. Now we always split dibosons, but
    got plotting plotSelectDY combines them.

 - The normalization interval is now hardwired in calcCrossSection.C as
bin numbers, this is not safe.
   This has been fixed.

 