
Analysis steps:

1. Running on AODSIM original data and producing Bambu-style
(i.e. MIT framework) ntuples. This is done by someone else
for everyone using that framework on all datasets of interest.
The Bambu ntuples of a given dataset are the same for all
analyses that use this framework.

2. Running on Bambu files and producing analysis specific 
ntuples is done for us (presently by Kevin Sung/MIT).
At present, we get in these ntuples for each event:
  - event information block (event/run/lumi section, etc)
  - generator information about gamma*/Z, each of the two
      two daughter leptons, etc
  - electron collection, contains all electrons >9 GeV
  - muon collection, contains all muons >10 GeV
  - photon collection, all superclusters with Et>9 GeV
  - jet collection, contains Particle Flow jets 
         with L1, L2, L3 corrected jet Et>10 GeV,
         or non-trivial b-tag
  - dielectron collection contains all possible pairs
        from the electron collection
  - primary vertex collection: all "good" primary vertices

3. Running on analysis specific ntuples. We use the script
"plotDY.C" or varitations of it. This script performs
the final selection of events. To the data, it applies
final energy scale corrections and recomputes invariant 
mass. This script also performs good run selection according
to the JSON file of choice.
   The result of running this script is seveal plots
that open on canvases, but more importantly it is 
creation of a new directory that contains a ROOT file
for each sample (data, signal MC, and all background MC
samples), each ROOT file contains an ntuple in a very
simple format of selected events only, with just a few
basic quantities.
   The script is run this way:
.L plotDY.C+   (the + is strongly recommended)
plotDY("data.conf")
where data.conf is the configuration file name.
  The configuration file contains many fields, I can explain
each line in a call.

4. On the final ntuples output of the above one runs
the script "plotSelectDY.C". This script makes plots
in the format appropriate for the notes and papers,
and also tabulates the yields for data and MC in 
several different ways. 
.L plotSelectDY.C+
plotSelectDY("data.conf")
The configuration file "data.conf" is identical to the
one in the previous bullet.
  There is also output of this step for all yields
saved in a ROOT file in form of TVectorD arrays.

5. The next script repackages observed yields,
performs backgrund subtraction, propagates background
errors, and creates the next level ROOT file that 
has arrays for background-subtracted signal yields
and errors (statistical and systematic).
This script can be run simply as
.x repackage_signal_yields.C
Note: up to this point, our background estimate comes
from MC. The MC backgrounds are used for example to make
plots that go into papers. But what we really use for the
measurement, is the backgrounds estimated from data-driven
methods (such as e-mu or fake rates methods). The "repackage"
script introduces these backgrounds, and therefore needs
the data-driven background values. At the moment, these
come from RAL, who produce them for us using our ntuples.

6. Calculate acceptance using signal MC.



-------------------------------------------

Open issues:

 1. FEWZ reweighting is not done for all analysis pieces. Should
 it be? For example for efficiency corrections?

 2. Pile-up reweighting is not done for all analysis pieces.
 For which should it be done? One should be careful and implement
 it coherently for event efficiency and efficiency from tag and probe.

 3. Now subtractBackgrounds.C wants split di-bosons, while for
 figures from plotSelectDY.C we have them combined. This should
 be reconciled.

 4. Understand mass-dependent efficiency. Especially ID.

 5. Add theory systematics to calcCrossSection.C
